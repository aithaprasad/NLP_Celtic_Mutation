{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1BJsDHImZsd8x5VZXf6foogJyGVph3WUu",
      "authorship_tag": "ABX9TyPctkaVS0Bez61Dmgn1Imbj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aithaprasad/NLP_Celtic_Mutation/blob/main/Celtic_Mutation_Scratch_Approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Reading the data from the respective files."
      ],
      "metadata": {
        "id": "GkoM9bV9Gn95"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bDzJv0rhv2O9"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "with open('celtic_train.tsv', encoding=\"utf-8\") as file:\n",
        "  f = csv.reader(file, delimiter=\"\\t\")\n",
        "  all_data = []\n",
        "  for line in f:\n",
        "    all_data.append(line)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('celtic_test.tsv', encoding=\"utf-8\") as test_file:\n",
        "  f = csv.reader(test_file, delimiter=\"\\t\")\n",
        "  all_test_data = []\n",
        "  for line in f:\n",
        "    all_test_data.append(line)"
      ],
      "metadata": {
        "id": "ytqga47nDWNy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7sB4SrVxq00",
        "outputId": "cb638328-4ca0-4468-f19f-2ab928313cbc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5057059"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtf0IDnADpAp",
        "outputId": "7047bc7f-d1bd-46a3-9302-2beafdf11f9e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "473951"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Function to just split the data. Re-used from the first competition"
      ],
      "metadata": {
        "id": "a3NGBEw_GzK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#def train_test_split(data, percent = 0.1):\n",
        "#    percent = int(percent * 10)\n",
        "\n",
        "#    train = data[((len(data) // 10) * percent):]\n",
        "#    test = data[:((len(data) // 10) * percent)]\n",
        "\n",
        "#    return train, test"
      ],
      "metadata": {
        "id": "SDZGj_dzyeFN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train, test = train_test_split(all_data)"
      ],
      "metadata": {
        "id": "SN3FqCTZ0ACc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = all_data, all_test_data"
      ],
      "metadata": {
        "id": "RBKO4ahQDsxA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### As we have five tags. The below code keeps the count of different tags on each unique word. I guess the names for the variables speak for what they actually are."
      ],
      "metadata": {
        "id": "fj5YyPudG-2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_tag_count = dict()\n",
        "N_count, S_count, U_count, T_count, H_count = 0, 0, 0, 0, 0 \n",
        "unique_words = []\n",
        "for word_tag in train:\n",
        "  word, tag = word_tag[0], word_tag[1]\n",
        "  \n",
        "  if word == \"<S>\": continue\n",
        "  \n",
        "  if tag == 'N': N_count += 1\n",
        "  elif tag == 'S': S_count += 1\n",
        "  elif tag == 'T': T_count += 1\n",
        "  elif tag == 'U': U_count += 1\n",
        "  else: H_count += 1\n",
        "\n",
        "  if word not in word_tag_count:\n",
        "    word_tag_count[word] = {tag : 1}\n",
        "    unique_words.append(word)\n",
        "  else:\n",
        "    if tag not in word_tag_count[word]: word_tag_count[word][tag] = 1\n",
        "    else: word_tag_count[word][tag] += 1"
      ],
      "metadata": {
        "id": "3hRALLA30PYZ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(word_tag_count))\n",
        "print(len(unique_words))\n",
        "print(N_count)\n",
        "print(S_count)\n",
        "print(T_count)\n",
        "print(U_count)\n",
        "print(H_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLcdmOJ47iI0",
        "outputId": "53227e1b-849f-4fe2-83fc-24864626ab86"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126547\n",
            "126547\n",
            "4139588\n",
            "493102\n",
            "17721\n",
            "165818\n",
            "40569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### We are manipulating the above \"word_tag_count\" dictionary with the probabilities(each word's tag has the probability of that tag for that word). For example, the word \"tug\". it is a 'S' with 0.005895380673796454 probability."
      ],
      "metadata": {
        "id": "cycC1igOHX8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_count_per_tag = {'N' : N_count, 'S': S_count, 'T' : T_count, 'U': U_count, 'H' : H_count}\n",
        "for word in unique_words:\n",
        "  new_dict = {'N' : 0, 'S': 0, 'T' : 0, 'U': 0, 'H' : 0}\n",
        "  tags = ['N', 'S', 'U', 'T', 'H']\n",
        "  for tag in tags:\n",
        "    if tag in word_tag_count[word]:\n",
        "      new_dict[tag] = word_tag_count[word][tag] / total_count_per_tag[tag] \n",
        "  word_tag_count[word] = new_dict"
      ],
      "metadata": {
        "id": "kd31cO0l7rHx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_count_per_tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBGqJvEkDi1S",
        "outputId": "60c50c01-6d9c-490a-e8a4-eaf91c66637b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'N': 4139588, 'S': 493102, 'T': 17721, 'U': 165818, 'H': 40569}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tag_count['tug']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOo7r3tkDl0y",
        "outputId": "80580589-4999-46ed-b40b-a49e624b22c9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'N': 1.9325594721020546e-06,\n",
              " 'S': 0.005877080198417366,\n",
              " 'T': 0,\n",
              " 'U': 0.00028344329324922506,\n",
              " 'H': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### We are constructing the dictionary which stores the context for each sentence like how many times a 'N' has followed 'N' or basically, how many times what tag is followed by what tag. "
      ],
      "metadata": {
        "id": "YQDvasPbIpe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_context_tag_count = {'<S>' : {'N': 0, 'S': 0, 'T': 0, 'U': 0, 'H': 0}, 'N' : {'N': 0, 'S': 0, 'T': 0, 'U': 0, 'H': 0}, \n",
        "                              'S' : {'N': 0, 'S': 0, 'T': 0, 'U': 0, 'H': 0}, 'T' : {'N': 0, 'S': 0, 'T': 0, 'U': 0, 'H': 0},\n",
        "                              'U' : {'N': 0, 'S': 0, 'T': 0, 'U': 0, 'H': 0}, 'H' : {'N': 0, 'S': 0, 'T': 0, 'U': 0, 'H': 0}}\n",
        "\n",
        "for i in range(1, len(train)):\n",
        "  if train[i][0] == '<S>': continue\n",
        "  word, tag = train[i][0], train[i][1]\n",
        "  prev_word, prev_tag = train[i - 1][0], train[i - 1][1]\n",
        "  if prev_word == '<S>': prev_tag = '<S>'\n",
        "  sentence_context_tag_count[prev_tag][tag] += 1"
      ],
      "metadata": {
        "id": "SFgubqMuDqpS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_context_tag_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obKx9v40H55u",
        "outputId": "57c0afdd-a90e-4355-ad13-e43500cbde53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<S>': {'N': 180588, 'S': 19093, 'T': 14, 'U': 351, 'H': 214},\n",
              " 'N': {'N': 3281024, 'S': 439585, 'T': 17657, 'U': 164746, 'H': 39313},\n",
              " 'S': {'N': 464177, 'S': 25486, 'T': 30, 'U': 578, 'H': 773},\n",
              " 'T': {'N': 16551, 'S': 1035, 'T': 3, 'U': 2, 'H': 53},\n",
              " 'U': {'N': 158600, 'S': 6335, 'T': 12, 'U': 106, 'H': 120},\n",
              " 'H': {'N': 38647, 'S': 1568, 'T': 5, 'U': 35, 'H': 96}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### We utilize the count and convert them to probabilities with 1-smoothing."
      ],
      "metadata": {
        "id": "igwyg0J7JGX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for tag in ['N', 'S', 'T', 'U', 'H', '<S>']:\n",
        "  total_tag_sum = sum(sentence_context_tag_count[tag].values())\n",
        "  for next_tag in ['N', 'S', 'T', 'U', 'H']:\n",
        "    sentence_context_tag_count[tag][next_tag] = (1 + sentence_context_tag_count[tag][next_tag]) / total_tag_sum"
      ],
      "metadata": {
        "id": "GpswQ9a4H8CH"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence_context_tag_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDwEthcMOHN7",
        "outputId": "93644fe2-11b1-477c-df39-b0dc96d0d481"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<S>': {'N': 0.9017726954958554,\n",
              "  'S': 0.09534605013482472,\n",
              "  'T': 7.490262658543893e-05,\n",
              "  'U': 0.0017577149705383002,\n",
              "  'H': 0.0010736043143912914},\n",
              " 'N': {'N': 0.8322563461916509,\n",
              "  'S': 0.11150425193255249,\n",
              "  'T': 0.0044790827747585495,\n",
              "  'U': 0.04178929946161212,\n",
              "  'H': 0.009972287926540811},\n",
              " 'S': {'N': 0.9452879986314872,\n",
              "  'S': 0.051903699057518266,\n",
              "  'T': 6.313079886934776e-05,\n",
              "  'U': 0.0011791204046887856,\n",
              "  'H': 0.0015762334943508118},\n",
              " 'T': {'N': 0.9381092722738608,\n",
              "  'S': 0.05871684425300385,\n",
              "  'T': 0.00022670596236681024,\n",
              "  'U': 0.00017002947177510768,\n",
              "  'H': 0.0030605304919519385},\n",
              " 'U': {'N': 0.9602114146985282,\n",
              "  'S': 0.038359780351510234,\n",
              "  'T': 7.870535741313653e-05,\n",
              "  'U': 0.0006478056340927391,\n",
              "  'H': 0.0007325652497684246},\n",
              " 'H': {'N': 0.9577953458402518,\n",
              "  'S': 0.03888379470149439,\n",
              "  'T': 0.0001486951996233055,\n",
              "  'U': 0.000892171197739833,\n",
              "  'H': 0.0024039057272434387}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### This is basically the predict function which is Viterbi, where we utlize the above probabilities and assign the probability for the tag and store the max state(probability till that point) and at the end we return the sentence and the respective predicted tags."
      ],
      "metadata": {
        "id": "M4f1AsBMJQMU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def viterbi(sentence):\n",
        "  state = []\n",
        "  tags = ['N', 'S', 'U', 'T', 'H']\n",
        "  for key, word in enumerate(sentence):\n",
        "    p = []\n",
        "    for tag in tags:\n",
        "      emission_p = 0\n",
        "      if key == 0 or word == '<S>': transmission_prob = sentence_context_tag_count['<S>'][tag]\n",
        "      else: transmission_prob = sentence_context_tag_count[state[-1]][tag]\n",
        "      if word in word_tag_count.keys(): emission_p = word_tag_count[word][tag]\n",
        "  \n",
        "      state_prop = emission_p * transmission_prob\n",
        "      p.append(state_prop)\n",
        "    max_value=max(p)\n",
        "    value=tags[p.index(max_value)]\n",
        "    state.append(value)\n",
        "  return list(zip(sentence, state)), state"
      ],
      "metadata": {
        "id": "bh0aquW2OI_J"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = []\n",
        "test_label = []\n",
        "for data in test:\n",
        "  if len(data) == 2:\n",
        "    test_data.append(data[0])\n",
        "    test_label.append(data[1])"
      ],
      "metadata": {
        "id": "Gzl8TZRnJ2rI"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_pairs, pred_val = viterbi(test_data)"
      ],
      "metadata": {
        "id": "GJVutQKdQLcF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_from_scratch(sentence_tag):\n",
        "  \n",
        "  correct = 0\n",
        "  sentence, tags = [], []\n",
        "  \n",
        "  for word, tag in sentence_tag:\n",
        "    sentence.append(word)\n",
        "    tags.append(tag)\n",
        "  \n",
        "  pred_labels = viterbi(sentence)\n",
        "  for i in range(len(tags)):\n",
        "    if pred_labels[1][i] == tags[i]:\n",
        "      correct += 1\n",
        "  \n",
        "  return correct\n"
      ],
      "metadata": {
        "id": "hjtO3wy5T1e_"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate():\n",
        "  total = 0\n",
        "  correct_from_scratch = 0\n",
        "  testfile = open('test.tsv', 'r')\n",
        "  sentence = []\n",
        "  for line in testfile:\n",
        "    total += 1\n",
        "    pieces = line.rstrip(\"\\n\").split(\"\\t\") \n",
        "    if pieces[0]=='<S>':\n",
        "      correct_from_scratch += predict_from_scratch(sentence)\n",
        "      sentence = []\n",
        "    else:\n",
        "      sentence.append(pieces)\n",
        "  correct_from_scratch += predict_from_scratch(sentence)\n",
        "  return correct_from_scratch/total"
      ],
      "metadata": {
        "id": "pF26Th8cRPRE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJsf9Z7rYLaJ",
        "outputId": "6fadb4e5-eee7-47d9-fdc8-d3a8cb11d63d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.870005"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##References:\n",
        "\n",
        "https://www.mygreatlearning.com/blog/pos-tagging/ \n",
        "\n",
        "I used this for some algo understanding purposes, but did not take any code from it."
      ],
      "metadata": {
        "id": "qJ-GBE3Nj9ML"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zcI80aWhkJF1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}